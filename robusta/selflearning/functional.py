# Copyright 2020-2021 Evgenia Rusak, Steffen Schneider, George Pachitariu
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#
#
# ---
# This licence notice applies to all originally written code by the
# authors. Code taken from other open-source projects is indicated.
# See NOTICE for a list of all third-party licences used in the project.

import torch.nn.functional as F


def gce(logits, target, q=0.8):
    """Generalized cross entropy.

    Reference: https://arxiv.org/abs/1805.07836
    """
    probs = F.softmax(logits, dim=1)
    probs_with_correct_idx = probs.index_select(-1, target).diag()
    loss = (1.0 - probs_with_correct_idx**q) / q
    return loss.mean()


def entropy(logits, target, q=0.8):
    """Entropy."""
    log_probs = F.log_softmax(logits, dim=1)
    probs = F.softmax(logits, dim=1)
    return -(probs * log_probs).sum(dim=-1).mean()
